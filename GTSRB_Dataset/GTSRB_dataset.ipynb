{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore Folder Structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = \"../input\"\ntrain_dir = os.path.join(base_dir, \"train\")\ntest_dir = os.path.join(base_dir, \"test\")\nnum_classes = len(os.listdir(train_dir))\nprint(\"Training folder contains\", len(os.listdir(train_dir)), \"folders(classes of images)\")\nprint(\"Testing folder contains\", len(os.listdir(test_dir)), \"images\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe = pd.read_csv(\"../input/Train.csv\")\ntest_dataframe = pd.read_csv(\"../input/Test.csv\")\ntrain_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keep only filenames in \"Path\" column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataframe[\"image\"] = train_dataframe[\"Path\"].apply(lambda x: x.split(\"/\")[-1])\ntest_dataframe[\"image\"] = test_dataframe[\"Path\"].apply(lambda x: x.split(\"/\")[-1])\ntrain_dataframe[\"ClassId\"] = train_dataframe[\"ClassId\"].apply(lambda x: str(x))\ntest_dataframe[\"ClassId\"] = test_dataframe[\"ClassId\"].apply(lambda x: str(x))\n\ntrain_dataframe.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understand the dataset Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"class_freq = pd.DataFrame()\nclass_freq[\"ClassId\"], class_freq[\"freq\"] = train_dataframe.ClassId.value_counts().index.astype(int), train_dataframe.ClassId.value_counts().values\nclass_freq[\"test_ClassId\"], class_freq[\"test_freq\"] = test_dataframe.ClassId.value_counts().index.astype(int), test_dataframe.ClassId.value_counts().values\n\nimport matplotlib.pyplot as plt\n\nplt.title(\"Data classes Distribution\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Frequency\")\nplt.xlim(0, 45)\nplt.ylim(200, 2400)\nplt.bar(class_freq[\"ClassId\"], class_freq[\"freq\"], color=\"green\", label=\"train_data\")\nplt.bar(class_freq[\"test_ClassId\"], class_freq[\"test_freq\"], color=\"red\", label=\"test_data\")\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Image data using ImageDataGenerator"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nbatch_size = 64\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range=0.2,zoom_range=0.2, horizontal_flip=True,\n                                   validation_split=0.20)\n\ntraining_set = train_datagen.flow_from_directory(\n                                                directory = train_dir,\n                                                target_size=(48, 48),\n                                                subset=\"training\",\n                                                batch_size=batch_size,\n                                                shuffle=True,\n                                                class_mode=\"categorical\")\n\nval_set = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size=(48, 48),\n                                                    subset=\"validation\",\n                                                    batch_size=batch_size,\n                                                    shuffle=True,\n                                                    class_mode=\"categorical\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding Image Shape distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook\ntraining_images = training_set.filenames\n\nshape = []\nfor image in tqdm_notebook(train_dataframe[\"Path\"]):\n    image = image.lower()\n    image = os.path.join(base_dir, image)\n    img = plt.imread(image)\n    h, w, c = img.shape\n    shape.append((image, h, w, c))\n\nshapes = pd.DataFrame(shape, columns=[\"Image\", \"Height\", \"Width\", \"Channels\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of Heights in images"},{"metadata":{"trusted":true},"cell_type":"code","source":"shape_freq = pd.DataFrame()\nshape_freq[\"shape\"], shape_freq[\"freq\"] = shapes.Height.value_counts().index.astype(int), shapes.Height.value_counts().values\n\n# Height vs counts\nplt.title(\"Shape Distribution\")\nplt.xlabel(\"Height\")\nplt.ylabel(\"Frequency\")\nplt.xlim(25, 80)\nplt.ylim(100, 1500)\nplt.bar(shape_freq[\"shape\"], shape_freq[\"freq\"], color=\"green\", label=\"train_data\")\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution of Width in images"},{"metadata":{"trusted":true},"cell_type":"code","source":"shape_freq = pd.DataFrame()\nshape_freq[\"shape\"], shape_freq[\"freq\"] = shapes.Width.value_counts().index.astype(int), shapes.Width.value_counts().values\n\n# Width vs counts\nplt.title(\"Shape Distribution\")\nplt.xlabel(\"Width\")\nplt.ylabel(\"Frequency\")\nplt.xlim(25, 80)\nplt.ylim(100, 1500)\nplt.bar(shape_freq[\"shape\"], shape_freq[\"freq\"], color=\"green\", label=\"train_data\")\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nn_epochs = 60\nn_channels = 3\ns = [1, 1, 1, 1]\npad = \"SAME\"\npool = [1, 2, 2, 1]\ns_pool = [1, 2, 2, 1]\n\n\ntf.reset_default_graph()\nsess = tf.Session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tf.placeholder(name=\"X\", shape=(None, 48, 48, n_channels), dtype=tf.float32)\nY = tf.placeholder(name=\"Y\", shape=(None, 43), dtype=tf.float32)\nkeep_prob = tf.placeholder(name=\"keep_prob\", dtype=tf.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_parameters(layer=None, kernel_size=3, n_channels=None, n_filters=None):\n    w_name = \"W\" + str(layer)\n    b_name = \"b\" + str(layer)\n    W = tf.get_variable(name=w_name, shape=[kernel_size,\n                         kernel_size, n_channels, n_filters],\n                        dtype=tf.float32,\n                         initializer=tf.contrib.layers.xavier_initializer(),\n                        regularizer=tf.contrib.layers.l2_regularizer(0.01))\n\n    b = tf.get_variable(name=b_name, dtype=tf.float32,\n                     initializer=tf.constant(0.01, dtype=tf.float32,\n                     shape=[n_filters]))\n\n    return W, b","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First Convolution Layer\n### Here we only increase the depth in convolution layer, Height and Width remains same\n* kernel_size <-- 3 * 3\n* stride <-- 1\n* filters <-- 16\n* padding <-- \"same\"\n* activation <-- \"relu\"\n\n## Pooling Layer\n### Reduce Height and Weight by a factor of 2\n* ksize <-- 2 * 2\n* stride <-- 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"ksize_filter_1 = 3\nn_filters_1 = 16\n\n# initialize Weights and Biases for layer 1\nW1, b1 = initialize_parameters(layer=1, kernel_size=ksize_filter_1, n_channels=n_channels, n_filters=n_filters_1)\n\nZ1 = tf.nn.conv2d(X, W1, strides=s, padding=pad)\nZ1 = tf.add(Z1, b1)\nA1 = tf.nn.relu(Z1)\n\nA1 = tf.nn.max_pool(A1, ksize=pool, strides=s_pool, padding=\"VALID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Second Convolution Layer\n### Here we only increase the depth in convolution layer, Height and Width remains same\n* kernel_size <-- 3 * 3\n* stride <-- 1\n* filters <-- 32\n* padding <-- \"same\"\n* activation <-- \"relu\"\n\n## Pooling Layer\n### Reduce Height and Weight by a factor of 2\n* ksize <-- 2 * 2\n* stride <-- 2\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"ksize_filter_2 = 3\nn_filters_2 = 32\n\n# initialize Weights and Biases for layer 2\nW2, b2 = initialize_parameters(layer=2, kernel_size=ksize_filter_2, n_channels=n_filters_1, n_filters=n_filters_2)\n\nZ2 = tf.nn.conv2d(A1, W2, strides=s, padding=pad)\nZ2 = tf.add(Z2, b2)\nA2 = tf.nn.relu(Z2)\n\nA2 = tf.nn.max_pool(A2, ksize=pool, strides=s_pool, padding=\"VALID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Third Convolution Layer\n### Here we only increase the depth in convolution layer, Height and Width remains same\n* kernel_size <-- 3 * 3\n* stride <-- 1\n* filters <-- 64\n* padding <-- \"same\"\n* activation <-- \"relu\"\n\n## Pooling Layer\n### Reduce Height and Weight by a factor of 2\n* ksize <-- 2 * 2\n* stride <-- 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"ksize_filter_3 = 3\nn_filters_3 = 64\n\n# initialize Weights and Biases for layer 3\nW3, b3 = initialize_parameters(layer=3, kernel_size=ksize_filter_3, n_channels=n_filters_2, n_filters=n_filters_3)\n\nZ3 = tf.nn.conv2d(A2, W3, strides=s, padding=pad)\nZ3 = tf.add(Z3, b3)\nA3 = tf.nn.relu(Z3)\n\nA3 = tf.nn.max_pool(A3, ksize=pool, strides=s_pool, padding=\"VALID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fourth Convolution Layer\n### Here we only increase the depth in convolution layer, Height and Width remains same\n* kernel_size <-- 3 * 3\n* stride <-- 1\n* filters <-- 128\n* padding <-- \"same\"\n* activation <-- \"relu\"\n\n## Pooling Layer\n### Reduce Height and Weight by a factor of 2\n* ksize <-- 2 * 2\n* stride <-- 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"ksize_filter_4 = 3\nn_filters_4 = 128\n\n# initialize Weights and Biases for layer 4\nW4, b4 = initialize_parameters(layer=4, kernel_size=ksize_filter_4, n_channels=n_filters_3, n_filters=n_filters_4)\n\nZ4 = tf.nn.conv2d(A3, W4, strides=s, padding=pad)\nZ4 = tf.add(Z4, b4)\nA4 = tf.nn.relu(Z4)\n\nA4 = tf.nn.max_pool(A4, ksize=pool, strides=s_pool, padding=\"VALID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Network in Network Convolution\n# Reduces the depth for easier computation\n* kernel_size <-- 1 * 1\n* stride <-- 1\n* filters <-- 32\n* padding <-- \"same\"\n* activation <-- \"relu\""},{"metadata":{"trusted":true},"cell_type":"code","source":"ksize_filter_5 = 1\nn_filters_5 = 32\n\n# initialize Weights and Biases for layer 5\nW5, b5 = initialize_parameters(layer=5, kernel_size=ksize_filter_5, n_channels=n_filters_4, n_filters=n_filters_5)\n\nZ5 = tf.nn.conv2d(A4, W5, strides=s, padding=pad)\nZ5 = tf.add(Z5, b5)\nA5 = tf.nn.relu(Z5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Flatten Layer followed by Fully Connected Layers\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use A5 if network in network to be used, helps in reducing computational cost\n# use A5 for without 1 * 1 convolution implemenatation\nlayer_shape = A4.get_shape()\nnum_features = layer_shape[1:4].num_elements()\nflatten = tf.reshape(A4, [-1, num_features])\nfc1_in = flatten.get_shape()[1:4].num_elements()\n\nFCW1 = tf.get_variable(name=\"FCW1\", shape=[fc1_in, 1024], dtype=tf.float32,\n                       initializer=tf.contrib.layers.xavier_initializer(),\n                       regularizer=tf.contrib.layers.l2_regularizer(0.01))\nFCb1 = tf.get_variable(name=\"FCb1\", shape=[1, 1024], dtype=tf.float32,\n                       initializer=tf.contrib.layers.xavier_initializer(),\n                       regularizer=tf.contrib.layers.l2_regularizer(0.01))\n\nFC1 = tf.add(tf.matmul(flatten, FCW1), FCb1)\nFC1 = tf.nn.relu(FC1)\nFC1 = tf.nn.dropout(FC1, keep_prob)\n\nFCW2 = tf.get_variable(name=\"FCW2\", shape=[1024, 256], dtype=tf.float32,\n                                   initializer=tf.contrib.layers.xavier_initializer(),\n                                   regularizer=tf.contrib.layers.l2_regularizer(0.01))\nFCb2 = tf.get_variable(name=\"FCb2\", shape=[1, 256], dtype=tf.float32,\n                                   initializer=tf.contrib.layers.xavier_initializer(),\n                                   regularizer=tf.contrib.layers.l2_regularizer(0.01))\n\nFC2 = tf.add(tf.matmul(FC1, FCW2), FCb2)\nFC2 = tf.nn.relu(FC2)\nFC2 = tf.nn.dropout(FC2, keep_prob)\n\nFCW3 = tf.get_variable(name=\"FCW3\", shape=[256, 43], dtype=tf.float32,\n                                   initializer=tf.contrib.layers.xavier_initializer(),\n                                    regularizer=tf.contrib.layers.l2_regularizer(0.01))\nFCb3 = tf.get_variable(name=\"FCb3\", shape=[1, 43], dtype=tf.float32,\n                                   initializer=tf.contrib.layers.xavier_initializer(),\n                                    regularizer=tf.contrib.layers.l2_regularizer(0.01))\n\nFC3 = tf.add(tf.matmul(FC2, FCW3), FCb3, name=\"final\")\n\n\n# Prediction\nprediction = tf.argmax(FC3,1)\npred_prob = tf.nn.softmax(FC3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cost Function and Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss Function\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=FC3, labels=Y)\n\n# Cost function\ncost = tf.reduce_mean(cross_entropy)\n\n# Evaluate model -- Accuracy\ncorrect_pred = tf.equal(prediction, tf.argmax(Y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n# Optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of batches\nnb_train = int(len(training_set.filenames) / batch_size) if len(training_set.filenames) % batch_size == 0 else int(len(training_set.filenames) / batch_size) + 1\nnb_val = int(len(val_set.filenames) / batch_size) if len(val_set.filenames) % batch_size == 0 else int(len(val_set.filenames) / batch_size) + 1\n\nprint(\"Training batches:\", nb_train)\nprint(\"val_batches:\", nb_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"init = tf.global_variables_initializer()\nsaver = tf.train.Saver()\nbest_acc = 0\nhistory = []\n\nwith tf.Session() as sess:\n    sess.run(init)\n    for i in tqdm_notebook(range(n_epochs)):\n        step = 0\n        total_loss = 0\n        total_acc = 0\n        val_total_loss = 0\n        val_total_acc = 0\n        for batch in range(nb_train):\n            batch_X, batch_Y = training_set.next()\n            # Optimize\n            sess.run(optimizer, feed_dict={X : batch_X, Y : batch_Y, keep_prob :  0.5})\n            if batch % 60 == 0:\n                # measure and display training accuracy and loss\n                train_loss, train_acc = sess.run([cost, accuracy], feed_dict={X : batch_X, Y : batch_Y, keep_prob : 1.0})\n                total_loss += train_loss\n                total_acc += train_acc\n                print(\"For Minibatch:\", str(batch), \"at epoch:\", str(i), \"Loss:\",train_loss,\n                      \" and acc:\", train_acc)\n                step += 1\n        total_loss /= step\n        total_acc /= step\n        \n        for batch in range(nb_val):\n            val_batch_X, val_batch_Y = val_set.next()\n            # measure and display validation accuracy and loss\n            val_loss, val_acc = sess.run([cost, accuracy], feed_dict={X : val_batch_X, Y : val_batch_Y, keep_prob : 1.0})\n            val_total_loss += val_loss\n            val_total_acc += val_acc\n        \n        val_total_loss /= nb_val\n        val_total_acc /= nb_val        \n        print(\"After Epoch\", str(i), \"Validation Loss:\", val_total_loss,\n                                      \" Validation Acc:\", val_total_acc)\n    \n        history.append((i, total_loss, total_acc, val_total_loss, val_total_acc))\n        \n        if  val_total_acc > 0.3 and val_total_acc > best_acc:\n            best_acc = val_total_acc\n            try:\n                save_path = saver.save(sess, \"/kaggle/working/gtsr_model.cpkt\")\n                print(\"Model Stored in path:\", save_path)\n            except Exception as e:\n                print(\"Model Not stored\")\n                print(e)\n    print(\"Optimization is DONE!!!!!\")\n    \ntry:\n    with tf.Session() as sess:\n        # Restore variables from disk.\n        saver.restore(sess, \"/kaggle/working/gtsr_model.cpkt\")\n        print(\"Model Restored\")\nexcept:\n    print(\"Model Not restored\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot Accuracy\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nhistory = pd.DataFrame(history, columns=[\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"])\n\n#  \"Accuracy\"\nplt.ylim(0.2,1)\nplt.xlim(1,n_epochs)\nplt.plot(history[:][\"epoch\"], history[:][\"train_acc\"], label=\"training_accuracy\", color=\"green\")\nplt.plot(history[:][\"epoch\"], history[:][\"val_acc\"], label=\"val_accuracy\", color=\"red\")\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.show()\n\nhistory.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"#  \"Loss\"\nplt.ylim(0.01, 1)\nplt.xlim(1,n_epochs)\nplt.plot(history[:][\"epoch\"], history[:][\"train_loss\"], label=\"training_loss\", color=\"green\")\nplt.plot(history[:][\"epoch\"], history[:][\"val_loss\"], label=\"val_loss\", color=\"red\")\nplt.title('model loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport glob\n\nprint(\"Testing Images\")\npreds = []\n\ntest_set = os.listdir(test_dir)\nprint(\"Testing: Images found \", len(test_set))\n\nsess = tf.Session()\n#Create a saver object to load the model\nsaver = tf.train.import_meta_graph(\"/kaggle/working/gtsr_model.cpkt.meta\")\n\n#restore the model\nsaver.restore(sess,\"/kaggle/working/gtsr_model.cpkt\")\n\n#Create graph object for getting the same network architecture\ngraph = tf.get_default_graph()\n\n#Get the last layer of the network by it's name which includes all the previous layers too\nFC3 = graph.get_tensor_by_name(\"final:0\")\n\n#Get the same placeholders (X, Y)\nX = graph.get_tensor_by_name(\"X:0\")\n              \n#Get the last layer of the network by it's name which includes all the previous layers too\nY = graph.get_tensor_by_name(\"Y:0\")\n\nkeep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\nfor image in tqdm_notebook(test_set):\n    if image.endswith(\".png\"):\n        image = os.path.join(test_dir, image)\n        img = cv2.imread(image)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (48, 48))\n        img = img / 255\n        img = img.reshape((-1, 48, 48, 3))\n        softm = tf.nn.softmax(FC3)\n        pred = sess.run(softm, feed_dict={X:img, keep_prob : 1.0})\n        pred_class = pred.argmax\n        preds.append([image.split(\"/\")[-1], pred_class])\ntest_output = pd.DataFrame(preds, columns=[\"image\", \"pred_ClassId\"])\ntest_output[\"pred_ClassId\"] = test_output[\"pred_ClassId\"].apply(\n                                    lambda x : str(x).replace(\"[\", \"\").replace(\"]\", \"\")) \ntry:\n    test_output.to_csv(\"/kaggle/working/test_output.csv\")\n    print(\"test output generated: test_output.csv\",)\nexcept:\n    print(\"Test output not generated\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.merge(test_dataframe, test_output, on=[\"image\"], how=\"inner\")\ntest_df[\"ClassId\"] = test_df[\"ClassId\"].apply(lambda x : str(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct_pred = test_df.where(test_df[\"ClassId\"] == test_df[\"pred_ClassId\"])[\"image\"]\nwrong_pred = correct_pred.isnull().sum()\n\nprint(\"Correct Predictions : \", (correct_pred.count() / test_df[\"Path\"].count()) * 100, \"%\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}